import streamlit as st
import librosa
import numpy as np
import requests
import tempfile
import os
from pydub import AudioSegment
import io
import wave
from scipy.signal import butter, lfilter
from collections import Counter

st.set_page_config(page_title="Music Key & Camelot Detector", page_icon="ðŸŽµ", layout="wide")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONSTANTES & PROFILS (ensemble pour plus de prÃ©cision)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NOTES_LIST = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']

PROFILES = {
    "krumhansl": {
        "major": [6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88],
        "minor": [6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17]
    },
    "temperley": {
        "major": [5.0, 2.0, 3.5, 2.0, 4.5, 4.0, 2.0, 4.5, 2.0, 3.5, 1.5, 4.0],
        "minor": [5.0, 2.0, 3.5, 4.5, 2.0, 4.0, 2.0, 4.5, 3.5, 2.0, 1.5, 4.0]
    },
    "aarden": {
        "major": [17.7661, 0.145624, 14.9265, 0.160186, 19.8049, 11.3587, 0.291248, 22.062, 0.145624, 8.15494, 0.232998, 18.6691],
        "minor": [18.2648, 0.737619, 14.0499, 16.8599, 0.702699, 14.5212, 0.737619, 19.8145, 5.84214, 2.68046, 2.51091, 9.84455]
    },
    "bellman": {
        "major": [16.8, 0.86, 12.95, 1.41, 13.49, 11.93, 1.25, 16.74, 1.56, 12.81, 1.89, 12.44],
        "minor": [18.16, 0.69, 12.99, 13.34, 1.07, 11.15, 1.38, 17.2, 13.62, 1.27, 12.79, 2.4]
    }
}

CAMELOT_MAP = {
    'C major': '8B', 'C# major': '3B', 'D major': '10B', 'D# major': '5B',
    'E major': '12B', 'F major': '7B', 'F# major': '2B', 'G major': '9B',
    'G# major': '4B', 'A major': '11B', 'A# major': '6B', 'B major': '1B',
    'C minor': '5A', 'C# minor': '12A', 'D minor': '7A', 'D# minor': '2A',
    'E minor': '9A', 'F minor': '4A', 'F# minor': '11A', 'G minor': '6A',
    'G# minor': '1A', 'A minor': '8A', 'A# minor': '3A', 'B minor': '10A'
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FONCTIONS UTILITAIRES AUDIO & FILTRAGE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def butter_lowpass(y, sr, cutoff=180, order=4):
    nyq = 0.5 * sr
    normal_cutoff = cutoff / nyq
    b, a = butter(order, normal_cutoff, btype='low', analog=False)
    return lfilter(b, a, y)


def apply_sniper_filters(y, sr):
    y_harm = librosa.effects.harmonic(y, margin=8.0)
    nyq = 0.5 * sr
    low = 60 / nyq
    high = 5000 / nyq
    b, a = butter(4, [low, high], btype='band')
    return lfilter(b, a, y_harm)


def get_bass_priority(y, sr):
    y_bass = butter_lowpass(y, sr, cutoff=150)
    chroma_bass = librosa.feature.chroma_cqt(y=y_bass, sr=sr, n_chroma=12)
    return np.mean(chroma_bass, axis=1)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DÃ‰TECTION TONALITÃ‰ (ensemble + boost basse + tierce/quinte)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def solve_key_sniper(chroma_vector, bass_vector):
    cv = (chroma_vector - chroma_vector.min()) / (chroma_vector.max() - chroma_vector.min() + 1e-8)
    bv = (bass_vector - bass_vector.min()) / (bass_vector.max() - bass_vector.min() + 1e-8)

    profile_scores = {f"{NOTES_LIST[i]} {mode}": [] for i in range(12) for mode in ["major", "minor"]}

    for p_name, p_data in PROFILES.items():
        for mode in ["major", "minor"]:
            for i in range(12):
                score = np.corrcoef(cv, np.roll(p_data[mode], i))[0, 1]

                # Boost mineur si dominante + sensible prÃ©sente
                if mode == "minor":
                    dom_idx, leading_idx = (i + 7) % 12, (i + 11) % 12
                    if cv[dom_idx] > 0.42 and cv[leading_idx] > 0.32:
                        score *= 1.18

                # Boost selon basse
                if bv[i] > 0.58:
                    score += bv[i] * 0.42

                # Renforcement harmonique (quinte + tierce)
                fifth_idx = (i + 7) % 12
                if cv[fifth_idx] > 0.48:
                    score += 0.14

                third_idx = (i + 4) % 12 if mode == "major" else (i + 3) % 12
                if cv[third_idx] > 0.46:
                    score += 0.10

                # TrÃ¨s fort tonic â†’ bonus
                if cv[i] > 0.52:
                    score += 0.48

                profile_scores[f"{NOTES_LIST[i]} {mode}"].append(score)

    avg_scores = {k: np.mean(v) for k, v in profile_scores.items() if v}
    if not avg_scores:
        return {"key": "Unknown", "score": 0.0}

    best_key = max(avg_scores, key=avg_scores.get)
    best_score = avg_scores[best_key]

    # VÃ©rification des candidats proches (ambiguÃ¯tÃ©)
    candidates = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)[:4]
    if len(candidates) >= 2:
        top_key, top_sc = candidates[0]
        sec_key, sec_sc = candidates[1]
        top_i = NOTES_LIST.index(top_key.split()[0])
        sec_i = NOTES_LIST.index(sec_key.split()[0])
        dist = min(abs(top_i - sec_i), 12 - abs(top_i - sec_i))
        if dist in [3, 4, 9] and (sec_sc / top_sc > 0.82):
            if bv[sec_i] > bv[top_i] + 0.06:
                best_key = sec_key
                best_score = sec_sc

    return {"key": best_key, "score": best_score, "top_candidates": [k for k, _ in candidates]}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SIMULATION ACCORD PIANO & PERCEPTION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def generate_piano_chord_audio(key_str, sr=22050, duration=2.0):
    root_note, mode = key_str.split()
    notes_freq = {
        'C':261.63, 'C#':277.18, 'D':293.66, 'D#':311.13, 'E':329.63,
        'F':349.23, 'F#':369.99, 'G':392.00, 'G#':415.30, 'A':440.00,
        'A#':466.16, 'B':493.88
    }

    intervals = [0, 4, 7] if mode == 'major' else [0, 3, 7]
    root_freq = notes_freq.get(root_note, 440.0)
    freqs = [root_freq * (2 ** (i / 12.0)) for i in intervals]

    t = np.linspace(0, duration, int(sr * duration), False)

    attack, decay, sustain, release = 0.01, 0.20, 0.60, duration - 0.21
    env = np.zeros_like(t)
    atk_end = int(attack * sr)
    dec_end = int((attack + decay) * sr)
    rel_start = int((duration - release) * sr)

    env[:atk_end] = np.linspace(0, 1, atk_end)
    env[atk_end:dec_end] = np.linspace(1, sustain, dec_end - atk_end)
    env[dec_end:rel_start] = sustain
    env[rel_start:] = np.linspace(sustain, 0, len(env) - rel_start)

    y = np.zeros_like(t)
    for f in freqs:
        for harm in range(1, 6):
            amp = 1.0 / harm
            y += amp * np.sin(2 * np.pi * f * harm * t)

    y *= env
    y = 0.5 * y / np.abs(y).max()
    y_int = (y * 32767).astype(np.int16)

    buf = io.BytesIO()
    with wave.open(buf, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sr)
        wf.writeframes(y_int.tobytes())
    buf.seek(0)
    return buf.read(), y


def simulate_ear_perception(chord_y, song_y, sr, chroma_song):
    stft_chord = np.abs(librosa.stft(chord_y))
    freqs = librosa.fft_frequencies(sr=sr)
    mag = np.mean(stft_chord, axis=1)

    peak_idxs = np.argsort(mag)[-12:]
    chord_freqs = freqs[peak_idxs]

    roughness = 0.0
    for i in range(len(chord_freqs)):
        for j in range(i+1, len(chord_freqs)):
            df = abs(chord_freqs[i] - chord_freqs[j])
            if 15 < df < 250:
                cbw = 0.25 * (chord_freqs[i] + chord_freqs[j]) / 2
                roughness += (mag[peak_idxs[i]] * mag[peak_idxs[j]]) * (df / cbw) ** 2

    consonance = 1 / (1 + roughness + 1e-6)

    chroma_chord = librosa.feature.chroma_stft(y=chord_y, sr=sr)
    chroma_chord_avg = np.mean(chroma_chord, axis=1)

    similarity = np.corrcoef(chroma_song, chroma_chord_avg)[0, 1]
    return 0.60 * similarity + 0.40 * consonance


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TRAITEMENT PRINCIPAL D'UN FICHIER (avec analyse segmentÃ©e + tuning)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def process_audio(file_bytes, file_name, sr_target=22050):
    ext = os.path.splitext(file_name)[1].lower()
    try:
        if ext == '.m4a':
            audio = AudioSegment.from_file(io.BytesIO(file_bytes), format="m4a")
            samples = np.array(audio.get_array_of_samples()).astype(np.float32)
            if audio.channels == 2:
                samples = samples.reshape(-1, 2).mean(axis=1)
            y = samples / 32768.0
            sr = audio.frame_rate
            if sr != sr_target:
                y = librosa.resample(y, orig_sr=sr, target_sr=sr_target)
                sr = sr_target
        else:
            with io.BytesIO(file_bytes) as buf:
                y, sr = librosa.load(buf, sr=sr_target, mono=True)
    except Exception as e:
        return {"error": str(e)}

    duration = librosa.get_duration(y=y, sr=sr)
    if duration < 8:
        return {"error": "fichier trop court (< 8s)"}

    # Estimation tuning pour ajustement
    tuning = librosa.estimate_tuning(y=y, sr=sr)

    y_filt = apply_sniper_filters(y, sr)

    # Analyse segmentÃ©e (max 8 segments pour vitesse)
    segment_len = max(10, min(30, duration / 8))
    num_segments = int(duration / segment_len)
    votes = Counter()
    chroma_global = np.mean(librosa.feature.chroma_cqt(y=y_filt, sr=sr, tuning=tuning, hop_length=512), axis=1)
    bass_global = get_bass_priority(y, sr)

    for seg in range(num_segments):
        start = seg * segment_len * sr
        end = min((seg + 1) * segment_len * sr, len(y_filt))
        y_seg = y_filt[int(start):int(end)]
        if len(y_seg) < sr * 5 or np.max(np.abs(y_seg)) < 0.01:  # Skip silence
            continue

        chroma_seg = np.mean(librosa.feature.chroma_cqt(y=y_seg, sr=sr, tuning=tuning, hop_length=512), axis=1)
        bass_seg = get_bass_priority(y[int(start):int(end)], sr)

        res = solve_key_sniper(chroma_seg, bass_seg)

        # Poids : plus au centre
        weight = 1.5 if 0.3 < (seg / num_segments) < 0.7 else 0.8
        votes[res["key"]] += res["score"] * weight

    if not votes:
        return {"error": "aucune tonalitÃ© dÃ©tectÃ©e"}

    initial_key = votes.most_common(1)[0][0]
    initial_score = votes[initial_key] / sum(votes.values())

    # Simulation perceptive sur top-4 candidats
    top_candidates = [k for k, _ in votes.most_common(4)]
    perception_scores = {}
    best_score_perc = -1
    best_key = initial_key
    best_audio = None

    for cand in top_candidates:
        audio_bytes, chord_y = generate_piano_chord_audio(cand, sr=sr)
        perc_score = simulate_ear_perception(chord_y, y, sr, chroma_global)
        perception_scores[cand] = perc_score

        if perc_score > best_score_perc + 0.05:  # Seuil sÃ©lectif augmentÃ©
            best_score_perc = perc_score
            best_key = cand
            best_audio = audio_bytes

    # Confiance finale (moyenne pondÃ©rÃ©e + plafonnement)
    final_conf = min(0.94, (initial_score * 0.6 + best_score_perc * 0.4))

    report = f"""Analyse terminÃ©e
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Fichier       : {file_name}
DurÃ©e         : {int(duration // 60):02d}:{int(duration % 60):02d}
FrÃ©quence     : {sr} Hz
Tuning est.   : {tuning:+.2f} cents

TonalitÃ©      : {best_key}
Camelot       : {CAMELOT_MAP.get(best_key, "??")}
Confiance     : {final_conf:.4f}

Scores perception :
""" + "\n".join(f"  {k:<12} : {v:.4f}" for k,v in sorted(perception_scores.items(), key=lambda x:x[1], reverse=True))

    report += "\n\nChroma global :\n" + "\n".join(f"  {k:<3} : {v:.4f}" for k,v in zip(NOTES_LIST, chroma_global))

    return {
        "key": best_key,
        "camelot": CAMELOT_MAP.get(best_key, "??"),
        "conf": final_conf,
        "audio_bytes": best_audio,
        "report": report,
        "adjusted": best_key != initial_key
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# INTERFACE STREAMLIT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.title("ðŸŽµ Music Key & Camelot Detector â€“ Advanced")
st.markdown("Multi-profils + filtrage basse + simulation perceptive des accords piano")

try:
    bot_token = st.secrets["TELEGRAM_BOT_TOKEN"]
    chat_id   = st.secrets["TELEGRAM_CHAT_ID"]
    secrets_ok = True
except KeyError:
    bot_token = chat_id = None
    secrets_ok = False

if not secrets_ok:
    st.info("Pour activer l'envoi Telegram : ajoutez TELEGRAM_BOT_TOKEN et TELEGRAM_CHAT_ID dans les secrets Streamlit.")

uploaded_files = st.file_uploader(
    "DÃ©posez vos fichiers audio",
    type=["mp3", "wav", "ogg", "flac", "m4a"],
    accept_multiple_files=True
)

if uploaded_files:
    total = len(uploaded_files)
    prog_global = st.progress(0)
    status_global = st.empty()

    container = st.container()

    for i, file in enumerate(uploaded_files, 1):
        prog_global.progress((i-1)/total)
        status_global.markdown(f"**Traitement {i}/{total} â†’** {file.name}")

        with st.status(f"Analyse â†’ {file.name}", expanded=(i==1)) as st_status:
            st_status.write("Chargement & prÃ©traitement...")
            data = process_audio(file.getvalue(), file.name)

            if "error" in data:
                st_status.update(label=f"Erreur : {data['error']}", state="error")
                continue

            st_status.update(label="TerminÃ© âœ“", state="complete", expanded=False)

            with container:
                st.markdown(f"### {file.name}")
                colA, colB = st.columns([4, 1])
                with colA:
                    st.markdown(f"**TonalitÃ© :** {data['key']}")
                    st.markdown(f"**Camelot :** <span style='font-size:2.4em; color:#f59e0b; font-weight:bold;'>{data['camelot']}</span>", unsafe_allow_html=True)
                    if data["adjusted"]:
                        st.caption("â†’ AjustÃ© via simulation perceptive")
                with colB:
                    st.metric("Confiance", f"{data['conf']:.3f}")

                st.audio(data["audio_bytes"], format="audio/wav")
                st.text_area("Rapport complet", data["report"], height=380)

                if secrets_ok:
                    if st.button("Envoyer rapport Telegram", key=f"tg_{i}_{hash(file.name)}"):
                        with st.spinner("Envoi..."):
                            url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
                            payload = {"chat_id": chat_id, "text": f"ðŸŽµ {file.name}\n\n{data['report']}", "parse_mode": "Markdown"}
                            try:
                                r = requests.post(url, data=payload, timeout=12)
                                if r.status_code == 200:
                                    st.success("EnvoyÃ©")
                                else:
                                    st.error(f"Erreur {r.status_code}")
                            except Exception as ex:
                                st.error(f"Ã‰chec : {str(ex)}")

                st.markdown("---")

    prog_global.progress(1.0)
    status_global.success(f"âœ“ {total} fichier(s) analysÃ©(s)")

st.markdown("<small>PrÃ©cision amÃ©liorÃ©e grÃ¢ce Ã  l'ensemble de profils + simulation d'accords piano + analyse segmentÃ©e. ~88â€“96 % selon le style musical.</small>", unsafe_allow_html=True)
